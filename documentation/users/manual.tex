% To do list for new releases: 
% - check accuracy of \currPyVersion
% 
% 

\documentclass[10pt]{article}
\setlength{\oddsidemargin}{0.in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-0.25in}
\setlength{\textheight}{8.25in}

% Prevent LaTeX from adding vertical space in the middle of 
% a page just to stretch the text to match textheight
\raggedbottom

% Skip space between paragraphs
\setlength{\parskip}{.05in}

% Put numbers in section and subsection headings, but not subsubsection headings
\setcounter{secnumdepth}{2}

% Specify by how much to indent paragraphs
\setlength{\parindent}{0ex}

% Use the natbib package for the bibliography
\usepackage[round]{natbib}
\bibliographystyle{sysbio}

% Use the graphicx package to incorporate and scale
% encapsulated postscript figures
\usepackage{graphicx}
\usepackage{floatflt}

% bold math
\usepackage{bm}

% cancel 
\usepackage{cancel}

% Make document single-spaced
\renewcommand{\baselinestretch}{1.0}

\usepackage{courier}	% http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/fonts.html
%\usepackage{upquote}
%\newfont{\mytt}{cmtt10 at 10pt}

\newcommand{\currPhycasVersion}{1.1.2}
\newcommand{\currPyVersion}{2.6.1}

\newcommand{\trademark}[1]{#1${}^{\mbox{\tiny TM}}$}
\newcommand{\pathname}[1]{{\em #1}}				% file name or file path
\newcommand{\objectname}[1]{{\tt #1}}				% name of an object of a class (e.g. mcmc)
\newcommand{\classname}[1]{{\tt #1}}				% name of a class (e.g. MCMC)
\newcommand{\menu}[1]{{\sf #1}}					% menu command
\newcommand{\keycmd}[1]{{\sf #1}}					% keyboard command
\newcommand{\code}[1]{{\tt #1}}					% typeset using typewriter font
\newcommand{\cmd}[1]{{\tt \small #1}\index{#1}}	% phycas commands (e.g. mcmc, sumt, etc.)
\newcommand{\opt}[2]{{\tt \small #1.#2}\index{#1!#2}}	% command options (e.g. 'type' for model command)
\newcommand{\optval}[1]{{\tt #1}}					% option values (e.g. 'gtr' for model.type option)
\newcommand{\term}[1]{{\bfseries #1}\index{#1}}	% new term

\newcommand{\important}[1]{{\bf Important: #1}}	% important information

\newcommand{\warning}[1]{{\bf Warning: #1}}		% warnings
\newcommand{\warnNoPyThree}{\warning{Do not install Python 3.x --- Phycas is not yet ready to make the leap to Python 3}}

\newcommand{\one}[1]{\mbox{${\bf 1}_{#1}$}}
\newcommand{\data}{{\bf y}}
\newcommand{\params}{\mbox{$\bm \theta$}}
\newcommand{\Var}{\mbox{Var}}

\newcommand{\pinvar}{\mbox{$p_{\mbox{invar}}$}}
\newcommand{\ncat}{\mbox{$n_{\mbox{cat}}$}}

\newcommand{\phycasapp}{\pathname{Phycas.app}}
\newcommand{\phycasicon}{\includegraphics[scale=0.2]{images/PhycasGUI}}

\newcommand{\Rii}[1]{-\sum_{i \neq #1} \pi_i \mu}

\newcommand{\ccdot}{c_{\cdot}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\ncateg}{n_{\tiny\mbox{cat}}}

\usepackage{amssymb} % for \blacktriangle symbol
\newcommand{\pointup}{$\blacktriangle$}

\newenvironment{indentednote}{
\begin{center}
\begin{minipage}{5.5in}
\rule{5.5in}{1pt} \par
\raggedright 
}{
\rule{5.5in}{1pt}
\end{minipage}
\end{center}
}

\newfont{\bftt}{cmtt10}

% Causes upright apostrophe (ASCII 27) to be used in verbatim rather than the 
% acute-accent-like apostrophe (ASCII 146), which causes problems when users 
% cut and paste from the manual into a Python source code file, where ASCII 146
% is not recognized
\usepackage{upquote}

% index stuff
\usepackage{makeidx}
\makeindex
%\index{cheese}			index entry
%\index{cheese!gouda} 		index subentry
%\index{cheese!gouda!brie}	index subsubentry
%\index{cheese|see{crackers}}	"see" entries
%\index{Kraft@\textit{Kraft}}	change font
%\index{cheese@gouda}		gouda right next to cheese, as if gouda were spelled cheese
\usepackage{phycas}

% Keep hyperref last among includes
\usepackage{hyperref}\hypersetup{backref, linkcolor=blue, urlcolor=blue, colorlinks=true, citecolor=blue, hyperindex=true, 
pdfstartview=FitB, 
pdfstartpage=1,
pdftitle={Phycas User Manual},
pdfauthor={Paul O. Lewis, Mark T. Holder, and David L. Swofford}, 
pdfsubject={Phycas User Manual},
pdfkeywords={phylogenetics, Bayesian, Markov chain Monte Carlo, MCMC}}
% pdfpagemode=FullScreen,  

\begin{document}

\title{{\sc Phycas User Manual} \\ Version \currPhycasVersion}
\author{Paul O. Lewis, Mark. T. Holder, and David L. Swofford}
\date{\today}
\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Phycas (\url{http://www.phycas.org}) is an extension of the Python programming language (\url{http://www.python.org}) that allows Python to read NEXUS-formatted data files, run Bayesian phylogenetic MCMC analyses, and summarize the results. In order to use Phycas, you need to first have Python installed on your computer. Please see section~\ref{sec:install} entitled ``Installing Phycas'' (p.~\pageref{sec:install}) for detailed installation instructions and useful information on topics important for using Phycas, such as how to obtain a command prompt for the operating system you are using. The following sections assume that you have successfully installed Phycas and have read section~\ref{sec:install}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{What's new in version 1.2?} %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This version adds support for data partitioning, changes the name of the \cmd{ps} command to \cmd{ss}, and adds the \cmd{cpo} command. Phycas supports a limited form of data partitioning at present in that topology and edge lengths are always linked across partition subsets and all other model parameters are unlinked. The name change from \cmd{ps} to \cmd{ss} reflects the fact that the primary purpose of the command is to use the Stepping Stone method, and ``ps'' stands for ``path sampling,'' a name that was never used even by the authors of the thermodynamic integration approach! Finally, the \cmd{cpo} command is identical to the \cmd{mcmc} command except that it saves the site log-likelihoods to a file and estimates the Conditional Predictive Ordinate for each site using those stored site log-likelihoods. See section \ref{cpo} for details. 

Other changes include the following:
\begin{itemize}
\item The process of specifying a master pseudorandom number seed has been simplified. You can now simply insert the command \code{setMasterSeed(13579)}\index{setMasterSeed} just after the \code{from phycas import *} command to set the master random number seed to the value 13579.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{What's new in version 1.1.x?} %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
These are bug-fix releases. For a description of the major bug fixed, see the section on the ``underflow'' bug in the BUGS file. For other changes, see the CHANGES file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{What's new in version 1.1?} %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{New features}
The \cmd{ps} and \cmd{sump} commands are new to version 1.1. The \cmd{ps} command allows computation of both the path sampling (a.k.a. thermodynamic integration) method of \citet{LartillotPhillippe2006} and the steppingstone sampling method introduced by \citet{XieLewisFanKuoChen2010}. See section \ref{marglike} on page \pageref{marglike} for details. The \cmd{sump} command provides an analog of the sump command in MrBayes, providing means, extremes, and credible intervals for model parameters based on samples saved in the parameter file.

\subsubsection{Bugs fixed}
Two memory leaks were fixed prior to this release. For a description of the leaks and what was done to fix them, see the section on the ``leaky'' bug in the BUGS file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{How to use this manual} %%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This manual begins with a description of some things you can do with Phycas that you cannot do with most other Bayesian phylogenetics software. Following this features section (section~\ref{sec:features}) is a tutorial showing you how to perform some simple analyses. This tutorial (sections~\ref{sec:warmup} to \ref{sec:definingpartitionmodel}) does not attempt to explain all possible settings. The online help system provides details about settings not mentioned in the tutorial. After these initial sections, the manual switches to reference style, detailing probability distributions (section~\ref{sec:probdist}) that can be used as priors, and describing the models of character evolution (section~\ref{sec:models}) available in Phycas. Toward the end you will find a discussion (section~\ref{sec:designprinciples}) of design principles (e.g. Why did we decide to extend Python rather than write a stand-alone program? Why is there no graphical interface?) followed by an annotated listing (section~\ref{sec:phycassettings}) of Phycas settings. The final section (section~\ref{sec:install}) is devoted to the details of getting Phycas (and Python) installed on your computer system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Features %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Features}\label{sec:features}

Phycas differs in some ways from other programs that conduct Bayesian phylogenetic analyses. The following sections are meant to highlight some of the features present in Phycas that are uncommon or absent in other programs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Slice sampling}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
Phycas makes extensive use of an MCMC method known as \term{slice sampling} \citep{Neal2003a}, whereas many programs use Metropolis-Hastings (MH) proposals to update model parameters during an MCMC analysis. The decision to use slice sampling in Phycas was based on the fact that the efficiency of slice samplers can be tuned as they run. In contrast, MH depends on tuning parameters that must be adjusted prior to sampling, an activity almost never performed in practice, leading to inefficient MCMC sampling for data sets that are not like those used when decisions were being made about default values of tuning parameters. In the final tally, a program using slice sampling behaves nearly identically to one using MH if the program using MH has been tuned prior to the analysis; however, Phycas saves you from having to worry about tuning by doing it automatically during the run. 

Phycas first attempts to adapt its slice samplers (one slice sampler is assigned to each model parameter) at the cycle specified by the setting \opt{mcmc}{adapt\_first}. Each subsequent adaptation occurs after twice as many cycles as the previous adaptation. After the first few adaptations there is usually little to be gained by adapting the slice samplers further, hence the increasingly long time periods between adaptations. 

Slice sampling can be used only for continuous model parameters, not for updating the tree topology. Phycas uses the \citet{LargetSimon1999} ``LOCAL move without a molecular clock'' to propose simultaneous changes in tree topology and edge lengths. Because edge length parameters are closely tied to the topology (and because there are so many of them!), it appears to be more efficient to use the LOCAL move rather than slice samplers to update edge lengths.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hierarchical models} \label{hierarchicalmodels}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
It is common still in Bayesian phylogenetics to use non-hierarchical models. In a non-hierarchical model, all parameters in the model can be found in the likelihood function. Edge lengths are parameters found in the likelihood function and, typically, a single Exponential distribution is used as the prior distribution for all edge lengths. The problem with this is that the edge length prior often has more of an effect than intended (the average tree length often responds to changes in the edge length prior mean) and researchers are often at a loss when deciding on an appropriate prior mean for edge lengths. It is possible to take an empirical Bayes approach, which involves estimating edge lengths under maximum likelihood and using the average estimated edge length as the mean of the prior. Bayesian purists eschew peeking at the data to help determine the prior, but how should one choose an appropriate prior distribution without using estimates? 

Phycas provides for the use of hierarchical models to solve this problem in a purely Bayesian way. In a hierarchical model, some parameters (called \term{hyperparameters}) are not found in the likelihood function. They are in this sense one level removed from the data, hence the use of the term ``hierarchical.'' In the case of edge lengths, Phycas can use a hyperparameter to determine the mean of the edge length prior distribution, taking this responsibility away from the researcher, who is relieved to learn that she now only needs to specify the parameters of the \term{hyperprior} --- the prior distribution of the hyperparameter. Because hyperparameters are one level (or more) removed from the data, the effects of arbitrary choices in the specification of the hyperprior is much less pronounced. In fact, just letting Phycas use its default hyperprior works well because it is vague enough that the hyperprior (determining edge length prior means) will begin to hover around a value appropriate for the data at hand. The effect is similar to the empirical Bayes approach, but you need not compromise your Bayesian principles and, rather than fixing the mean of the edge length prior, you are effectively estimating it as the MCMC analysis progresses.

To tell Phycas to use a hierarchical model for edge lengths, you need only set \opt{mcmc}{using\_hyperprior} to \code{True}. The hyperprior distribution is determined by the setting \opt{mcmc}{edgelen\_hyperprior}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Polytomy priors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A solution to the ``Star Tree Paradox'' problem was proposed by \citet*{LewisHolderHolsinger2005}. Their solution was to use reversible-jump MCMC to allow unresolved tree topologies to be sampled during the course of a Bayesian phylogenetic analysis in addition to fully-resolved tree topologies. If the time between speciation events is so short (or the substitution rate so low) that no substitutions occurred along a particular internal edge in the true tree, then use of the \term{polytomy prior} proposed by \citet*{LewisHolderHolsinger2005} can improve inference by giving the Bayesian model a ``way out.'' That is, it is not required to find a fully resolved tree, but is allowed to place a lot of posterior probability mass on a less-than-fully-resolved topology. Please refer to the \citet*{LewisHolderHolsinger2005} paper for details.

To use the polytomy prior in an analysis, be sure that \opt{mcmc}{allow\_polytomies} and \opt{mcmc}{polytomy\_prior} are both \code{True}. The setting \opt{mcmc}{topo\_prior\_C} determines the strength of the polytomy prior. Setting \opt{mcmc}{topo\_prior\_C} to 1.0 results in a flat prior (all topologies have identical prior probabilities, and thus unresolved topologies get no more or less weight than fully-resolved topologies). Setting \opt{mcmc}{topo\_prior\_C} greater than 1.0 favors less resolved topologies more than fully-resolved ones. This is usually what is desired; even with a prior that favors unresolved trees, a fully-resolved topology can easily win out over a less-resolved one if there is even scant evidence for substitution along the relevant edge. In the paper, this value was set to the value $e$ (the base of the natural logarithms). To do this in Phycas, set \opt{mcmc}{topo\_prior\_C} equal \code{math.exp(1.0)}.

The example \pathname{$<$phycas install directory$>$/phycas/Examples/Paradox/Paradox.py} shows a complete example of an analysis using the polytomy prior. If executed, this example script will recreate the analysis presented in Figure 4 of the \citet*{LewisHolderHolsinger2005} paper.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Marginal Likelihoods} \label{marglike} %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Phycas offers several ways of estimating marginal (model) likelihoods. The marginal likelihood represents the average fit of the model to the data (as measured by the likelihood), where the average is a weighted average over all parameter values, the weights being provided by the joint prior distribution. If you initiate an MCMC analysis using the \cmd{mcmc} command, Phycas reports the marginal likelihood using the well-known harmonic mean method introduced by \citet{NewtonRaftery1994}. The {\em harmonic mean method} is widely known to overestimate the marginal likelihood, not penalizing models enough for having extra parameters that do not substantially increase the overall fit of the model. In addition, the variance of the harmonic mean estimator can be infinite, making this estimator potentially very unreliable.

Phycas can use two alternatives to the harmonic mean method --- {\em thermodynamic integration} \citep{LartillotPhillippe2006} (also known as path sampling), and the {\em stepping stone method} \citep{XieLewisFanKuoChen2010,FanWuChenKuoLewis2010} --- but only if the MCMC analysis is conducted using the \cmd{ss} command. The thermodynamic integration (TI) and stepping stone (SS) methods both require running a special MCMC analysis that explores a series of {\em power posterior} distributions. The power posterior is proportional to $L(\theta)^{\beta} p(\theta)^{\beta} \pi(\theta)^{1-\beta}$, where $L(\theta)$ is the likelihood, $p(\theta)$ is the prior, $\pi(\theta)$ is a ``reference distribution'' and $\beta$ is the power. 

By default, the \cmd{ss} command estimates the marginal likelihood using the version of the SS method described by \citet{FanWuChenKuoLewis2010}. In this version of SS, which is in effect if the setting \opt{ss}{scubed} is set to \code{True}, the reference distribution is a parameterized version of the prior distribution. That is, the first step of the analysis gathers samples from the posterior distribution, and the mean and variance of each parameter from this posterior sample is used to create a version of the prior distribution that approximates the posterior. For a simple example, if a model has two parameters and a Normal prior was associated with each parameter, then the reference distribution would be an uncorrelated bivariate normal distribution in which the marginal means and variances equal the sample means and variances of the two parameters from the initial posterior sample. The value of $\beta$ is slowly decreased from 1 (in which MCMC is exploring the posterior distribution) to 0 (in which MCMC is exploring the reference distribution) in small steps. The number of $\beta$ values used is specified by \opt{ss}{nbetavals} and the minimum and maximum $\beta$ values are set using \opt{ss}{minbeta} and \opt{ss}{maxbeta} (it is best to leave these set to their default values of 0 and 1, respectively). When the command \cmd{ss} is invoked, an MCMC analysis is run for each of the \opt{ss}{nbetavals} values of $\beta$. The current settings of the \cmd{mcmc} command are used for each value of $\beta$; however, the \opt{mcmc}{burnin} setting governs only the initial burn-in period (i.e. there is no separate burnin between successive values of $\beta$). At the end of the run, Phycas will report the log of the marginal likelihood estimated using the SS method.

In PS, as well as the version of SS described by \citet{XieLewisFanKuoChen2010}, the reference distribution, $\pi(\theta)$, equals the prior, $p(\theta)$. Phycas will provide marginal likelihood estimates for PS and this original version of SS if \opt{ss}{scubed} is set to \code{False}. \citet{XieLewisFanKuoChen2010} found that choosing $\beta$ values that are not equally spaced along the path from 1 to 0 substantially improves the efficiency of both TI and this version of SS. Best practice appears to place most $\beta$ values close to 0. Phycas uses evenly-spaced quantiles of a Beta($a$,$b$) distribution to choose $\beta$ values, where the two shape parameters of the Beta distribution, $a$ and $b$, are specified as \opt{ss}{shape1} and \opt{ss}{shape2}, respectively. By default, \opt{ss}{shape1} and \opt{ss}{shape2} are both set to 1.0, but when \opt{ss}{scubed} is set to \code{False}, you should also change \opt{ss}{shape1} to a small value such as 0.3 (leaving \opt{ss}{shape2} equal to 1.0). 

The example \pathname{$<$phycas install directory$>$/phycas/Examples/Steppingstone/Steppingstone.py} shows a complete example of the use of path/steppingstone sampling for marginal likelihood estimation. This example recreates part of Figure 10 in the \citet{XieLewisFanKuoChen2010} paper.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conditional Predictive Ordinates}\label{cpo}\index{Conditional predictive ordinates}\index{CPO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Conditional predictive ordinates (CPO) provide a way to assess the fit of the model to each site individually, much like the analysis of residuals in a regression analysis. The CPO for site $i$ equals $p(y_i|y_{(i)})$, where $y_i$ represents the data for site $i$ and $y_{((i)}$ represents all data {\em except} that for site $i$. CPOs are thus a form of cross-validation in which the predictive distribution from all data except that from site $i$ is used to predict the data observed at site $i$. The CPO for site $i$ is a measure of the success of the prediction, with high values meaning the data for site $i$ can be accurately predicted by a model based on all other data, and low values meaning that predictions made from a model trained on all other data would often fail to correctly predict the data at the focal site. Note that Phycas reports CPO values on the log scale, and thus these values are always negative (a log(CPO) equal to 0.0 would be equivalent to a probability of 1.0, which would be seen only for a tree in which all edge lengths are zero).

To get Phycas to calculate CPO values, specify \code{True} for \opt{mcmc}{save\_sitelikes}. This will cause Phycas to save a (sometimes very large) ``sitelikes'' file containing the site log-likelihoods for every site for every sample. Thus, if your alignment comprises 2000 sites and you specify \opt{mcmc}{ncycles} to be 10000 and \opt{mcmc}{sample\_every} to be 10, then this file will contain 1000 rows and 2000 columns. The name of the file produced can be specified with \opt{mcmc}{out.sitelikes} setting (the file will be named \code{sitelikes.txt} by default). You must used the command \cmd{sump} to summarize this file after the analysis is finished. Set the option \opt{sump}{cpofile} equal to a string specifying the name of the file of site likelihoods produced by the \cmd{mcmc} command. You must specify \opt{sump}{cpofile} even if you did not modify \opt{mcmc}{out.sitelikes} because, by default, the \cmd{sump} command does not even look for a file of site likelihoods to summarize. In its summary, the \cmd{sump} command will use the harmonic mean of the site likelihoods in one column of the sitelikes file as the estimate of the CPO for the site represented by that column. (If you calculate these in some other program, such as Excel, note that the estimator equals the log of the harmonic mean of the sampled site likelihoods, not the harmonic mean of the sampled site log-likelihoods.) While the harmonic mean method is unstable for estimating the overall marginal likelihood, it provides a stable and accurate method for estimating CPO values. The \cmd{sump} command will not only output the overall log CPO (calculated as the sum over sites of the log CPO at each site), but will generate a file containing the commands for generating a plot of log(CPO) vs. site in the software R (\url{http://www.r-project.org/}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Warming up to Phycas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Warming up to Phycas} \label{sec:warmup}

Phycas is an extension of Python, so to use it you must first start Python. In this section, you will learn how to invoke Phycas commands from the Python command line. After you become familiar with the basic commands, you will probably want to create a file containing the Phycas commands for a particular analysis. Creating such a file (a Python \term{script}) makes it easier to remember exactly what analyses you performed at some later time. If you want to redo an analysis, having the commands in a script file means you do not have to type the majority of the commands over again. We will switch to using scripts in section~\ref{sec:basic} (``A basic analysis'').

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{First things first}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

The way Phycas is run depends on the operating system you are using. If you are using the Windows or Linux versions, you start Phycas by opening a terminal (in Windows this is referred to as a ``console window'' or ``command prompt'') and typing \code{python} to invoke Python. If you are using a Mac, you will have downloaded the \phycasapp\ bundle that is built around the open-source terminal program iTerm (\url{http://iterm.sourceforge.net/}). Starting \phycasapp\ by double-clicking the Phycas icon automatically starts an iTerm terminal, invokes Python, and loads Phycas.

% The Phycas icon looks like this: \phycasicon

\subsubsection{Starting from a terminal on Windows}
To start Python on Windows, open a console window (a.k.a. terminal window) and type the word \code{python}. This should generate output similar to the following:
\begin{verbatim}
Python 2.5.1 (r251:54863, Oct 30 2007, 13:54:11) 
[GCC 4.1.2 20070925 (Red Hat 4.1.2-33)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> 
\end{verbatim}

At the \code{>>>} prompt, type \code{from phycas import *}, like this:
\begin{verbatim}
>>> from phycas import *
>>>
\end{verbatim}

Phycas is an ``extension'' of Python, but you must import extensions in order for their capabilities to be available. The import statement you typed means ``import everything phycas has to offer.'' 

\subsubsection{Starting from the \phycasapp\ bundle under MacOS}

\begin{floatingfigure}[l]{2cm}
\includegraphics[scale=0.4]{images/PhycasGUI}  
%\caption{Phycas icon}
\end{floatingfigure} If you are using the \phycasapp\ bundle on MacOS, you can launch the Phycas application by double clicking on the icon. Although the name appears to be just \pathname{Phycas}, it is really \phycasapp; the MacOS hides the \pathname{.app} extension unless you change this in the Finder preferences. (We will hereafter use the terms \term{Phycas application} and \term{Phycas.app} bundle interchangeably.) The Phycas application will show up in your dock and the window that appears will be a terminal that has already invoked Python and issued the ``from phycas import *'' command mentioned in the previous section.

All the instructions for the rest of the manual will be executed the same way regardless of whether Phycas running from a Windows console window, a Linux terminal or the \pathname{Phycas} application.

%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Getting help}
%%%%%%%%%%%%%%%%%%%%%%%%%
Now type \cmd{help} at the Python prompt. This will display the following help message:
\begin{verbatim}
>>> help
Phycas Help
    
For Python Help use "python_help()"

Commands are invoked by following the name by () and then
hitting the RETURN key. Thus, to invoke the sumt command use:

sumt()

Commands (and almost everything else in python) are case-sensitive -- so
"Sumt" is _not_ the same thing as "sumt" In general, you should use the
lower case versions of the phycas command names.

The currently implemented Phycas commands are:
  
like                           randomtree
mcmc                           ss
model                          sump                               

Use <command_name>.help to see the detailed help for each command. So,

sumt.help

will display the help information for the sumt command object.
\end{verbatim}

Ordinarily, typing \cmd{help} will invoke the {\em Python} help system; however, note that after Phycas has been imported into Python, typing \cmd{help} now invokes the {\em Phycas} help system. You can still access Python's interactive help by typing \cmd{python\_help()}\footnote{If you do try typing \cmd{python\_help()}, note that you can quit the Python help system (and return to using Phycas) by typing \cmd{quit} at the \code{help>} prompt}. Hopefully, the output is self-explanatory, so let's try what the output of the \cmd{help} command suggests: obtaining help for a particular command. Type the following at the Python prompt:
\begin{verbatim}
>>> model.help
model
Defines a substitution model.

Available input options:
Attribute                      Explanation
============================== =================================================
type                           Can be 'jc', 'hky' or 'gtr'

update_relrates_separately     If True, GTR relative rates will be individually
                               updated using slice sampling; if False, they will
                               be updated jointly using a Metropolis-Hastings
                               move (generally both faster and better).

relrate_prior                  The joint prior distribution for all six GTR
                               relative rate parameters. Used only if
                               update_relrates_separately is False.

relrate_param_prior            The prior distribution for individual GTR
                               relative rate parameters.  Used only if
                               update_relrates_separately is true.

relrates                       The current values for GTR relative rates. These
                               should be specified in this order: A<->C, A<->G,
                               A<->T, C<->G, C<->T, G<->T.

fix_relrates                   If True, GTR relative rates will not be modified
                               during the course of an MCMC analysis
...                               
Current model input settings:
Attribute                      Current Value
============================== =================================================
type                           'hky'
update_relrates_separately     True
relrate_prior                  Dirichlet((1.00000, 1.00000, 1.00000, 1.00000,
                               1.00000, 1.00000))
relrate_param_prior            Exponential(1.00000)
relrates                       [1.0, 4.0, 1.0, 1.0, 4.0, 1.0]
fix_relrates                   False
kappa_prior                    Exponential(1.00000)
kappa                          4.0
fix_kappa                      False
num_rates                      1
gamma_shape_prior              Exponential(1.00000)
gamma_shape                    0.5
fix_shape                      False
...
flex_prob_param_prior          Exponential(1.00000)
============================== =================================================

>>>
\end{verbatim}

You will probably need to scroll up to see all of the output of the \cmd{model.help} command. Only a portion of the output has been shown (as indicated by the ellipses). The output shows what model options are available and, at the end, the current values for those options. Thus, we see that \opt{model}{type} can be one of three things (\optval{'jc'}, \optval{'hky'} or \optval{'gtr'}) and that the current model type is \optval{'hky'}. Suppose you wanted to use the GTR model rather than the HKY model. You can do this by changing the \opt{model}{type} option as follows:
\begin{verbatim}
>>> model.type = 'gtr'
>>> model.current
\end{verbatim}
Entering \code{model.current} shows the list of current values, allowing you to confirm that your change has been made.

The quotes around \optval{'gtr'} are important. They indicate to Python that you are specifying a \term{string} (a series of text characters) rather than the name of some other sort of object. If you typed \code{gtr} without the quotes, Python would assume you are referring to a variable. Because it will (presumably) not find a variable by that name, you will get the following error message if you forget the quotes:
\begin{verbatim}
>>> model.type = gtr
Error: name 'gtr' is not defined
\end{verbatim}
Note that python is forgiving about whether you use double-quotes to delimit strings or single-quotes -- either will work to tell Python that you mean a string rather than the name of a variable.
Do not be confused by the subtle differences in typesetting within this manual. In all cases you should use plain quotes in Python (not the ``back-tick'' character or any special curved quote that is found in some word-processing programs).

The option \opt{model}{kappa\_prior} specifies the prior probability distribution to use for the transition/transversion rate ratio. Phycas defines several probability distributions for use as priors. In this case, the current value of \optval{Exponential(1.00000)} indicates that the $\kappa$ parameter will be assigned an exponential(1) prior distribution. See section~\ref{sec:probdist} (p.~\pageref{sec:probdist}) for a complete list of probability distributions available within Phycas.

The option \opt{model}{relrates} specifies the values of the six GTR relative rates parameters. The square brackets around the value of the \opt{model}{relrates} parameter, \optval{[1.0, 4.0, 1.0, 1.0, 4.0, 1.0]}, indicate that you should specify the six relative rate values as a Python \term{list}. The description (``The current values for GTR relative rates. These should be specified in this order: A$<$-$>$C, A$<$-$>$G, A$<$-$>$T, C$<$-$>$G, C$<$-$>$T, G$<$-$>$T.'') indicates the expected order for the six relative rate values. The \opt{model}{relrates} option and others like it, such as \opt{model}{kappa}, \opt{model}{state\_freqs}, \opt{model}{gamma\_shape}, and \opt{model}{pinvar} are used for a variety of purposes: (1) to set the starting values for an MCMC analysis (the \cmd{mcmc} command); (2) to specify the values of parameters for simulations (the \cmd{sim} command); or (3) to specify the values of parameters for calculating the likelihood (the \cmd{like} command).

The \opt{model}{fix\_relrates} command is used to specify whether the relative rates are to be allowed to vary during an MCMC analysis (\opt{model}{fix\_relrates}=\optval{False}) or are to be frozen at the values specified by \opt{model}{relrates} (\opt{model}{fix\_relrates}=\optval{True}). The values \optval{True} and \optval{False} are known to Python and should not be surrounded by quotes (note also that case is important: typing \code{true} or \code{TRUE} will generate a ``not defined'' error message from Python).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% A basic analysis %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A basic analysis} \label{sec:basic}

The next task is to create a Python script containing the commands to carry out a basic MCMC analysis. A Python script is a file containing Python source code (including Phycas commands). When submitted to the Python interpreter (a computer program), the commands in the script file are read and executed.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Before proceeding...}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Exit your current Python session by typing \keycmd{Ctrl-d} (MacOS or Linux) or \keycmd{Ctrl-z} (Windows). If you are using \phycasapp\ on MacOS, type \keycmd{Ctrl-d} one more time to exit the terminal shell (this will make the iTerm window disappear). 

Create a new, empty directory (a.k.a. folder) in which to experiment. Copy the file \pathname{green.nex} into the new directory. This file can be found under your Phycas installation directory at the location \pathname{phycas/Tests/Data/green.nex}. If you have no idea where your Phycas installation directory is located, please refer to the relevant subsection of the installation instructions (either section~\ref{subsubsec:installfolderwindows} if you are using Windows, or section~\ref{subsubsec:installfoldermac} if you are using a Mac).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The {\em basic.py} script}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Create a new (plain text\footnote{It is important to save the file using plain text format. Most word processing programs, such as \trademark{Microsoft} \trademark{Word}, save files by default in a format that contains a lot of extra, proprietary information. All such programs have the option to save the file as plain text. It is best to create Python scripts using an editor that {\em only} saves files as plain text. Examples (for \trademark{Windows}) include Notepad++ and Pythonwin (or the simple Notepad program that comes with \trademark{Windows}). For Macs, Text Wrangler or BBEdit are good choices. Python comes with its own editor, named Idle, that is also a good (if slightly sluggish) choice. jEdit (\url{http://www.jedit.org/}) is a Java-Based text editor that works well on all platforms.}) file in the folder (which should contain only the file \pathname{green.nex}). Name the new file \pathname{basic.py} and type (or copy/paste) the following lines into the file:
\begin{verbatim}
from phycas import *
mcmc.data_source = 'green.nex'
mcmc.out.log = 'basic.log'
mcmc.out.log.mode = REPLACE
mcmc.out.trees.prefix = 'green'
mcmc.out.params.prefix = 'green'
mcmc.ncycles = 2000
mcmc.sample_every = 10
mcmc()
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line-by-line explanation} \label{subsec:basicpyexplanation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{samepage}
\begin{verbatim}
from phycas import *
\end{verbatim}
\pointup\ When you first start Python, it knows nothing about Phycas. You must import the functionality provided by Phycas before any of the Phycas commands described in this manual will work. This first line tells the Python interpreter to import everything (the asterisk symbol means ``everything'') from the \code{phycas} module. This line should start every Phycas script you create.\footnote{Note that you do {\em not} need to type this line if you are using the MacOS version of Phycas (although it doesn't hurt to enter \code{from phycas import *} again). The MacOS version of Phycas automatically executes this line before presenting you with the Python prompt.}
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.data_source = 'green.nex'
\end{verbatim}
\pointup\ This line specifies that the data should be read from the file named \code{green.nex}. In our case, \code{green.nex} is in the same directory as this script, but if it were in a different folder then you would need to specify a relative or absolute path to the file\footnote{
%
For example, if the data file was in a directory named \code{xyz} at the same level as the directory containing the script, set \opt{mcmc}{data\_source} to \code{'../xyz/green.nex'} }.
%
Phycas does not do anything at this point in the script except create a DataSource object that will read the file \code{'green.nex'} and make the \opt{mcmc}{data\_source} field refer to this object. The file name is specified as a string, so surround the file name with single quotes so that the Python interpreter will not complain. 

\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.out.log = 'basic.log'
\end{verbatim}
\pointup\ This line starts a log file, which captures all output sent to the console. Some consoles do not have a large buffer, and it is possible to lose the beginning of the output if an analysis runs for a long time. Note that the name of the log file must be in the form of a Python string: that is, failing to surround the file name with quotes will result in an error.
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.out.log.mode = REPLACE
\end{verbatim}
\pointup\ This line specifies the mode for the log file. The mode of any output file determines what happens if a file by that name already exists. The default behavior is to create a file by the same name but with a number at the end. For example, if \pathname{basic.log} already exists, then the new log file would be named \pathname{basic1.log}. If \pathname{basic1.log} already exists, then the new log file would be named \pathname{basic2.log}, and so on. You can also specify \code{REPLACE} (as we have done here) to replace any existing file with the same name, or \code{APPEND} to add to the end of an existing file. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.out.trees.prefix = 'green'
\end{verbatim}
\pointup\ This line specifies that the trees sampled during the MCMC analysis will be saved to a file having the prefix \pathname{green}. Phycas will add the extension \pathname{.t} to the end of the prefix you specify, so the full file name will be \pathname{green.t}. If you preferred, you could specify the entire file name using \code{mcmc.out.trees = 'green.t'} and \code{mcmc.out.trees.mode} could be used to specify Phycas' behavior if the file specified already exists.
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.out.params.prefix = 'green'
\end{verbatim}
\pointup\ This line specifies that the parameters sampled during the MCMC analysis will be saved to a file having the prefix \pathname{green}. Phycas will add the extension \pathname{.p} to the end of the prefix you specify, so the full file name will be \pathname{green.p}. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.ncycles = 2000
\end{verbatim}
\pointup\ The option \opt{mcmc}{ncycles} determines the length of the MCMC run. Cycles in Phycas are {\em not} the same as generations in MrBayes. About two orders of magnitude {\em fewer} Phycas cycles are needed than MrBayes generations, so a 2000 cycle Phycas run corresponds (roughly) to a 200,000 generation MrBayes run. This does not mean that Phycas runs faster (or slower) than MrBayes; it simply means that Phycas does more work during a single ``cycle'' than MrBayes does in one ``generation.''\footnote
%
{To compare the speed of MrBayes with Phycas, you should compare the time it takes, on average, to calculate the likelihood, which is the most computationally expensive task either program performs. Phycas reports this average value at the end of a run. MrBayes computes the likelihood roughly one time per generation if you specify \code{mcmcp nrun=1 nchain=1}. Also, be sure to compare the two programs under the same model and on the same dataset and with the same computer!}
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.sample_every = 10
\end{verbatim}
\pointup\ The option \opt{mcmc}{sample\_every} determines how many cycles elapse before the tree and model parameters are sampled. In this case, a sample is saved every 10 cycles, so a total of 200 trees (and 200 values from each model parameter) will be saved from this run.
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc()
\end{verbatim} 
\pointup\ This begins an MCMC analysis using defaults for everything except the options that you modified (\opt{mcmc}{data\_file\_name}, \opt{mcmc}{log\_file\_name}, \opt{mcmc}{ncycles} and \opt{mcmc}{sample\_every}). To see what additional settings can be changed before calling the \code{mcmc} method, either type \cmd{mcmc.help} at the Python prompt or see section~\ref{subsec:mcmcsettings} on page~\pageref{subsec:mcmcsettings}.

\subsubsection{Invoking phycas commands}
For Phycas commands such as \cmd{mcmc}, adding the parentheses after the name of the command generally serves to start the analysis that the command implements. 
There are exceptions to this rule. 
For example, the ``action'' associated with the \cmd{model} command is simply the creation of a copy of the model for purposes of saving the current model settings. 
Thus, you could issue the following command:
\begin{verbatim}
m1 = model()
\end{verbatim}
to save the current model settings to a variable named \code{m1}\footnote
%
{The name ``m1'' here is arbitrary, but you should be careful to avoid using names that are identical to those Phycas uses. For example, if you named your model ``mcmc'', then you would lose the ability to perform an MCMC analysis because you have redifined the name ``mcmc'' to mean something else!}
%
. Why would you want to save your model? It is necessary to save the model if you are planning to partition your data because the partitioning commands require you to specify a model (e.g. ``m1'') along with the set of sites to which that model applies. You will read more about partitioning in section~\ref{subsec:partitioning} on page~\pageref{subsec:partitioning}.

The \code{randomtrees()} invocation returns a \code{TreeCollection} that holds a set of simulated trees and is another example of a command that does not produce visible output.
\end{samepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Running \pathname{basic.py}} \label{subsec:runningbasicpy}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{If you are using Windows...} 

To execute the \pathname{basic.py} script you just created, open a console window, navigate\footnote{We suggest you read section~\ref{subsubsec:winconsole}, where a registry trick is described that enables you to open a console window positioned at a particular directory by right-clicking the name of the folder in and Explorer or My Computer window. This saves having to navigate to the directory after opening the console window, which can be a very tedious and time consuming operation if the directory in which your script resides is nested deep inside your file system.} to the directory containing the script and type the following at the command prompt:
%
\begin{verbatim}
python basic.py
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{If you are using MacOS...} 

Locate your \pathname{basic.py} file in a Finder window, then drag it onto the \phycasapp\ icon \phycasicon. (NOTE: be sure to drop the \pathname{basic.py} file, NOT the data file, onto the \phycasapp\ icon.) It should start running immediately and leave you with a Python prompt \code{>>>} when it is finished. Press \keycmd{Ctrl-d} twice (once to exit Python, a second time to exit the iTerm session).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Regardless of your operating system...} 

The program should run for a few minutes, creating three files (\pathname{basic.log}, \pathname{green.t} and \pathname{green.p}) as it runs. The file \pathname{green.t} is the tree file containing the trees sampled during the MCMC run, while \pathname{green.p} is the parameter file containing samples of model parameters. These files are equivalent to their counterparts in MrBayes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A word about pseudorandom numbers in Phycas} \label{subsec:rng}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

You will notice that if you run \pathname{basic.py} twice, the results will differ slightly the second time. This is because Phycas seeds its pseudorandom number generator using the system clock, and as a result, an entirely different series of pseudorandom numbers is used for the second MCMC analysis compared to the first MCMC analysis. The results are comparable, and both are equally valid, but most of the time you would like to have the option of exactly repeating an analysis (for example, you might want to make the Phycas script used to obtain the results for a published paper available to reviewers or the scientific community). To do this in Phycas, you must use the \cmd{setMasterSeed} command.

Here is a revised script (named \pathname{repeatable.py}) that does exactly what \pathname{basic.py} did, but is repeatable. It should produce exactly the same output every time it is run:
\begin{verbatim}
from phycas import *

setMasterSeed(98765)

mcmc.data_source = 'green.nex'
mcmc.out.log = 'repeatable.log'
mcmc.out.log.mode = REPLACE
mcmc.out.trees.prefix = 'green'
mcmc.out.params.prefix = 'green'
mcmc.ncycles = 2000
mcmc.sample_every = 10
mcmc()
\end{verbatim}
There is one new line in this script:

\begin{samepage}
\begin{verbatim}
setMasterSeed(98765)
\end{verbatim}
Pseudorandom numbers (as the name suggests) are not really random, but they behave for all intents and purposes like random numbers. One difference between the numbers generated by Phycas' pseudorandom number generator and real random numbers is that the former are repeatable given the same starting seed, which should be a positive integer (whole number). Here we've set the seed to the number 98765. Be sure to invoke the \cmd{setMasterSeed} command just after the \cmd{from phycas import *} command; if you set the master seed after Phycas begins using pseudorandom numbers, then your results will differ from run to run.
\end{samepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Summarizing tree files %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summarizing tree files}

Phycas provides the \cmd{sumt} method for summarizing an input tree file. While analogous, Phycas' \cmd{sumt} method differs somewhat from the MrBayes sumt command. The example below stands alone, however there is no reason why you could not place the following statements after the \cmd{mcmc} call in the previous \pathname{basic.py} example. For now, however, create a new file named \pathname{summarize.py} (in the same folder housing \pathname{basic.py}), enter the text of the example script below into the file, and save the file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example script}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{verbatim}
from phycas import *
sumt.trees = 'green.t'
sumt.out.trees.prefix = 'trees'
sumt.out.splits.prefix = 'splits'
sumt.burnin = 1
sumt()
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line-by-line explanation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{samepage}
\begin{verbatim}
from phycas import *
\end{verbatim}
\pointup\ These two lines were explained previously in the explanation of the \pathname{basic.py} script on page~\pageref{subsec:basicpyexplanation}. (This line would not be necessary if the \code{sumt} commands were appended to the end of \pathname{basic.py}.)
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt.trees = 'green.t'
\end{verbatim}
\pointup\ The setting \opt{sumt}{trees} specifies the name of the (input) tree file to be analyzed. Here, we are specifying the tree file produced by the analysis performed by \pathname{basic.py}. The file named here should be a valid NEXUS tree file, but need not be a file produced by Phycas.
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt.out.trees.prefix = 'trees'
\end{verbatim}
\pointup\ The setting \opt{sumt}{out.trees.prefix} specifies the prefix used to create (output) file names for a tree file (prefix + \pathname{.tre}) and a pdf file (prefix + \pathname{.pdf}). Both files will contain the same trees, but the trees in the pdf file are graphically represented whereas those in the tree file are in the form of newick (nested parentheses) tree descriptions. The first tree in each file is the 50\% majority-rule consensus tree, followed by all distinct tree topologies sampled during the course of the MCMC analysis that are in the specified credible set (the 95\% credible set by default). The graphical versions in the pdf file have edge lengths drawn proportional to their posterior means and with posterior probability support values shown above each edge. With the exception of the majority rule consensus tree, the titles of trees reflect their frequency in the samples. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt.out.splits.prefix = 'splits'
\end{verbatim}
\pointup\ The setting \opt{sumt}{out.splits.prefix} specifies the prefix used to create a file name for a pdf file containing two plots. The first plot in the file is similar to an AWTY \citep[][\url{http://king2.scs.fsu.edu/CEBProjects/awty/awty_start.php}]{Nylander:2008p471} cumulative plot. It shows the split posterior probability calculated at evenly-spaced points throughout the MCMC run (as if the MCMC run were stopped and split posteriors computed at that point in the run). This kind of plot gives you information about whether the Markov chain converged with respect to split posteriors. (Often, when plots of log-likelihoods or model parameters show apparent convergence, split posteriors are still changing, making this type of plot a better indicator of convergence.) This first plot is not identical to an AWTY cumulative plot. The most striking difference is the fact that the lines plotted all originate at zero (AWTY does not plot these initial segments). Also, in AWTY the x-axis is labeled in terms of generations, whereas the Phycas equivalent labels the x-axis in terms of samples. 

The second plot in this file shows split sojourns. A split sojourn is a sequence of successive samples in which the split is present in the sampled tree, preceded and followed by an absence of the split. The number and duration of split sojourns gives an indication of how well the Markov chain is mixing, and this plot shows the results graphically. Neither plot in this file shows results for trivial splits (the split separating a single taxon from all other taxa; such splits are always present and are thus guaranteed to have split posterior 1.0) or for splits that were present in every sample (these are not useful from the standpoint of assessing convergence or mixing, except that poor mixing might be indicated if very few splits are plotted). See \citet{LewisLewis2005} for an example of the use of split sojourns to assess convergence. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt.burnin = 1
\end{verbatim}
\pointup\ The setting \opt{sumt}{burnin} is the number of sampled tree topologies to skip. This value should always be at least 1 because the first tree in the tree file is the starting tree, which is never a valid sample from the posterior distribution. All statistics computed by the \cmd{sumt} method are based on the number of sampled trees remaining after the burn-in trees have been removed from consideration. For example, if there are 101 trees in the input tree file, and \opt{sumt}{burnin} is 1, all posterior probabilities will be computed using 100 in the denominator (not 101).
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt()
\end{verbatim}
\pointup\ The \cmd{sumt} method call begins the analysis of the input tree file. Besides the three files produced containing trees and plots, output is generated by this method summarizing the tree topologies and splits discovered. Each summary table includes the following information:
\end{samepage}
\begin{description}
\item[freq.] The number of trees in which the split or topology was found
\item[prob.] The frequency divided by the total number of trees sampled
\item[cum] For topologies, the cumulative posterior probability over all tree topologies sorted from most to least probable. This column aids in finding credible sets of trees. For example, the 95\% credible set of tree topologies would be all those above (and including) the first one having a cumulative probability at least 0.95.
\item[weight] In the case of splits, this is the posterior mean edge length of the split, obtained by averaging the edge length associated with the split over all sampled trees in which the split was found
\item[TL] In the case of tree topologies, this is the posterior mean tree length associated with a topology, obtained by averaging the tree length associated with the topology over all sampled trees having that topology
\item[s0] This is the first sample in which the split or tree topology appeared. The minimum possible value of this quantity is 1, and the maximum is the number of trees sampled.
\item[sk] This is the last sample in which the split or tree topology appeared. The minimum possible value of this quantity is 1, and the maximum is the number of trees sampled.
\item[k] This is the number of sojourns made by the split or tree topology. A sojourn is a sequence of sampled trees in which the split or topology appears, preceded and followed by a sampled tree lacking that split or topology.
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Running \pathname{summarize.py}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using the same procedure outlined in section~\ref{subsec:runningbasicpy}, run your \pathname{summarize.py} script. This will produce the files \pathname{trees.tre}, \pathname{trees.pdf} and \pathname{splits.pdf}. You can open the PDF files and view or print the figures therein.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Defining a partition model %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Defining a partition model}\label{sec:definingpartitionmodel}

This section describes \term{partitioning}, which is dividing your data set into subsets of sites and applying a separate model to each subset. We will use the term \term{partition} to mean ``wall'' and a \term{partitioning} to mean a particular division of sites into mutually-exclusive subsets. This differs from common usage, where the term partition is used to mean a subset of sites, but is in line with mathematical usage of the term.

To create a \term{partition model} in Phycas, you first define models for all subsets and then apply the models to the appropriate sets of sites. Phycas always treats tree topology and branch lengths as ``linked'' across partition subsets, and always treats all other parameters as ``unlinked'', to use MrBayes' terminology. There is no way to tell Phycas to unlink branch links, and likewise there is no way to tell it to use the same value of the gamma shape parameter for two different partition subsets. To create an unpartitioned model, simply change the settings on the current model object (as we did in the previous section) and, by default, that model will be applied to all sites.

I will use the following specification to illustrate how to set up a partitioned model and then you will be given the chance to apply it to real protein-coding gene set. The model that we will set up separates first, second and third codon positions. You will apply a separate K80+G model to the first and second codon positions and an HKY+G model to third positions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The {\em partition.py} script}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Create a new file in a folder containing the file \pathname{green.nex}. Name the new file \pathname{partition.py} and type (or copy/paste) the following lines into the file:
\begin{verbatim}
from phycas import *

# Set up K80+G model
model.type="hky"
model.state_freqs = [0.25, 0.25, 0.25, 0.25]
model.fix_freqs = True
model.kappa = 2.0
model.kappa_prior = BetaPrime(1.0, 1.0)
model.num_rates = 4
model.gamma_shape = 0.5
model.gamma_shape_prior = Exponential(1.0)

# Save the K80+G model 
m1 = model()
m2 = model()

# Set up and save the HKY+G model
model.fix_freqs = False
m3 = model()

# Define partition subsets
first  = subset(1, 1296, 3)
second = subset(2, 1296, 3)
third  = subset(3, 1296, 3)

# Start the run
mcmc()

# Summarize the posterior
sumt.trees = 'trees.t'
sumt()
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line-by-line explanation} \label{subsec:partitionpyexplanation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{samepage}
\begin{verbatim}
from phycas import *
\end{verbatim}
\pointup\ This line, which must begin all Phycas Python scripts, loads all Phycas functionality into Python.
\end{samepage}

\begin{samepage}
\begin{verbatim}
# Set up K80+G model
\end{verbatim}
\pointup\ This is a comment\index{comments}, and is thus ignored by Python. It serves merely to describe what the following lines are all about. Python treats everything following a hash character (\code{\#}) as a comment. Comments provide a great way to temporarily disable a line of code that you otherwise want to retain (i.e. you may want to re-activate it later). Simply insert a hash character at the beginning of the line and that line will be ignored until the hash character is later removed.
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.type="hky"
\end{verbatim}
\pointup\ This \opt{model}{type} command converts the current model into the HKY model (or, in this case, a variant of the HKY model).
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.state_freqs = [0.25, 0.25, 0.25, 0.25]
model.fix_freqs = True
\end{verbatim}
\pointup\ The K80 model differs from the HKY model in that the base frequencies are equal. The \opt{model}{state\_freqs} setting sets the frequencies all to 0.25, and setting \opt{model}{fix\_freqs} to \code{True} ensures that Phycas will not try to change these during an MCMC analysis.
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.kappa = 2.0
model.kappa_prior = BetaPrime(1.0, 1.0)
\end{verbatim}
\pointup\ The \opt{model}{kappa} setting sets the starting value of the transition/transversion rate ratio \code{kappa} ($\kappa$) to 2.0. The setting \opt{model}{kappa\_prior} sets the prior distribution to use for the $\kappa$ parameter. The BetaPrime distribution is a peculiar probability distribution that is nevertheless nice for parameters such as kappa (the transition/transversion rate ratio). Applying a BetaPrime(1,1) distribution to kappa is equivalent to MrBayes' use of a Beta(1,1) distribution for this case. In MrBayes, the transition/transversion rate ratio is modeled as a Beta variable. If $p$ is a Beta random variable, then MrBayes is treating $p/(1-p)$ as the ratio of transition rate to transversion rate. That is, $\kappa = p/(1-p)$. This is a little strange, since the prior distribution applies to $p$, not $\kappa$. Applying a BetaPrime prior distribution to kappa ($\kappa$) is equivalent to MrBayes' treatment, but in this case the prior is applied to the parameter $\kappa$. Using a BetaPrime distribution is not without peculiarity, however. For example, the mean of a BetaPrime(1,1) distribution is not defined. Nevertheless, it is a proper prior distribution and behaves quite well.
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.num_rates = 4
\end{verbatim}
\pointup\ The setting \opt{model}{num\_rates} adds the ``+G'' part of the model; it tells Phycas to use a discrete Gamma among-site rate heterogeneity submodel with 4 rate categories. If \opt{model}{num\_rates} were set to 1, rate homogeneity would be assumed. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.gamma_shape = 0.5
model.gamma_shape_prior = Exponential(1.0)
\end{verbatim}
\pointup\ The \opt{model}{gamma\_shape} setting establishes the starting value (0.5) for the gamma shape parameter, which determines the amount of rate heterogeneity. The prior for this parameter (often symbolized by $\alpha$) is set using the \opt{model}{gamma\_shape\_prior}.
\end{samepage}

\begin{samepage}
\begin{verbatim}
m1 = model()
m2 = model()
\end{verbatim}
\pointup\ Because we need to create a different model for the third codon positions, it is important at this point to save the model we've just set up. Calling the model as if it were a function (by following the word \code{model} by empty parentheses, e.g.\code{model()}) saves the model in its current state to a variable. The name of the variable is up to you. Here, I've been rather unimaginative and just saved the model twice under the variable names \code{m1} and \code{m2}. These will later be assigned to subsets of sites corresponding to the first and second codon positions, respectively.
\end{samepage}

\begin{samepage}
\begin{verbatim}
model.fix_freqs = False
m3 = model()
\end{verbatim}
\pointup\ Now that we've saved the model, we can modify it again for third positions. The only difference between the K80+G model and the HKY+G model is that in the HKY model base frequencies are not all fixed to the value 0.25, so we only need one line (\code{model.fix\_freqs = False}) to convert the model from K80+G to HKY+G. The line \code{m3 = model()} makes a copy of this model, assigning the copy to the variable \code{m3}.
\end{samepage}

\begin{samepage}
\begin{verbatim}
first  = subset(1, 1296, 3)
second = subset(2, 1296, 3)
third  = subset(3, 1296, 3)
\end{verbatim}
\pointup\ We must next define the subsets of sites corresponding to first, second and third codon positions. This process is analogous to creating charsets in PAUP or MrBayes. The variable names \code{first}, \code{second} and \code{third} can be any legal Python variable name (e.g. you could call them \code{a}, \code{b} and \code{c} instead). The \cmd{subset} command takes 3 arguments: start, stop and step. Start and stop specify the first and last site in the range, and setting step to 3 means ``take every 3rd site in that range.'' You can specify only start and stop if you want; in this case step is assumed to be 1.
\end{samepage}

\begin{samepage}
\begin{verbatim}
partition.addSubset(first, m1, "First codon positions")
partition.addSubset(second, m2, "Second codon positions")
partition.addSubset(third, m3, "Third codon positions")
partition()
\end{verbatim}
\pointup\ The final step is to assign models \code{m1}, \code{m2} and \code{m3}, to subsets \code{first}, \code{second} and \code{third}. These \cmd{addSubset} commands each take 3 arguments: subset, model and name. The name argument is least important; it is only used to refer to these subsets when reporting information about the partition model in the output. Just make sure to use quotes (single or double) around the name so that it is a valid Python string. Calling partition like a function (fourth line) freezes the partitioning scheme, telling Phycas that you are finished defining subsets.
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc()
\end{verbatim}
\pointup\ Now that the model has been defined, an MCMC analysis can be initiated using the \cmd{mcmc} command. Because this is just a tutorial, we will just assume default values for things like \opt{mcmc}{ncycles}, \opt{mcmc}{sample\_every}, etc., but you can use \opt{mcmc}{help} to get a description of all available settings, or \opt{mcmc}{curr} to get a concise summary of the available settings along with their current values.
\end{samepage}

\begin{samepage}
\begin{verbatim}
sumt.trees = 'trees.t'
sumt()
\end{verbatim}
\pointup\ Finally, let's follow the \cmd{mcmc} command with a \cmd{sumt} command to provide a summary of the posterior distribution of trees. The setting \opt{sumt}{trees} tells the \cmd{sumt} command what file to process. (The \cmd{sumt} command does not assume a default file name for the tree file to process, so the name of the file to process must be declared explicitly.)
\end{samepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Running \pathname{partition.py}} \label{subsec:runningpartitionpy}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Run the \pathname{partition.py} in Python as described for \pathname{basic.py} (see section \ref{subsec:runningbasicpy} on page \pageref{subsec:runningbasicpy}). In the end, you should several files. The files \pathname{params.p}, \pathname{trees.t} and \pathname{mcmcoutput.txt} were produced by the \cmd{mcmc} command. The files \pathname{sumtoutput.txt}, \pathname{sumt\_splits.pdf}, \pathname{sumt\_trees.pdf} and \pathname{sumt\_trees.tre} were produced by the \cmd{sumt} command.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Estimating the marginal likelihood using the stepping stone method %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Estimating the marginal likelihood using the stepping stone method}\label{sec:marginallikelihood}
There are two papers \citep{FanWuChenKuoLewis2010,XieLewisFanKuoChen2010} describing the stepping stone (SS) method, but at this time (5 July 2010) neither one has been published. The paper by \citet{FanWuChenKuoLewis2010} describes the method used below. Both papers are available upon request.

To estimate the marginal likelihood using the steppingstone method, a special MCMC analysis is conducted that begins by exploring the posterior distribution but transitions slowly to exploring a reference distribution.  The reference distribution is similar to the actual prior in that the joint reference distribution comprises a product of independent probability distributions, but differs from the actual prior in that a sample from the posterior distribution is used to inform the reference distribution. For example, if the sample posterior mean and variance of a particular branch length parameter is available, the component of the reference distribution associated with that branch length would be a Gamma distribution with this mean and variance. 

Technically, the distribution explored by Phycas when performing a steppingstone analysis is a "power posterior" distribution:

\[f_{\beta}(\theta|y) = \left[ f(y|\theta) p(\theta) \right]^{\beta} \left[ \pi_0(\theta) \right]^{1 - \beta}\]

Note that when $\beta = 1$, the power posterior equals the posterior (the reference distribution term $\pi_0(\theta)$ disappears), whereas when $\beta = 0$, the first term disappears leaving only the reference distribution. During an analysis, $\beta$ begins at 1 (posterior) and is decreased every \opt{mcmc}{ncycles} cycles until, ultimately, it equals 0 (reference distribution) for the last \opt{mcmc}{ncycles} cycles. The number of $\beta$ values visited equals \opt{ss}{nbetavals}. The period of time at the beginning spent exploring the posterior is not actually used by the stepping stone method, but is required if a pre-existing sample from the posterior is not available for the purpose of parameterizing the reference distribution. Phycas allows you to spend longer on this first step (see \opt{ss}{xcycles}) in order to obtain a better posterior sample.

The way the stepping stone method works is to attempt to estimate well a series of ratios of normalizing constants. Each ratio in the series represents a stepping stone along a path bridging the posterior to the reference distribution. The product of the ratios in this series provides an estimate of the marginal likelihood. The estimate of each ratio is based on samples taken from an MCMC analysis that is exploring the power posterior associated with one particular value of $\beta$ (the $\beta$ value associated with the denominator of each ratio). Letting subscripts represent $\beta$ values, here is the entire series assuming that 5 $\beta$ values (0.8, 0.6, 0.4, 0.2, and 0.0) were visited during the course of the analysis:

\[\frac{c_{1.0}}{c_{0.0}} = \left(\frac{c_{1.0}}{\cancel{c_{0.8}}}\right) \left(\frac{\cancel{c_{0.8}}}{\cancel{c_{0.6}}}\right) \left(\frac{\cancel{c_{0.6}}}{\cancel{c_{0.4}}}\right) \left(\frac{\cancel{c_{0.4}}}{\cancel{c_{0.2}}}\right) \left(\frac{\cancel{c_{0.2}}}{c_{0.0}}\right)\]

Note that the denominator of one ratio cancels the numerator of the adjacent ratio so that the product of all ratios is $c_{1.0}/c_{0.0}$. The value $c_{1.0}$ is the normalizing constant when $\beta = 1.0$, and thus is the quantity of interest: the normalizing constant of the posterior distribution (otherwise known as the marginal likelihood). The value $c_{0.0}$ is the normalizing constant when $\beta = 0.0$ (reference distribution), which is always equal to 1.0.

Why estimate all those ratios if almost everything cancels? The answer is that, like jumping a creek, it helps to have stepping stones. Estimating the ratio $c_{1.0}/c_{0.0}$ is difficult because even though the reference distribution is made to be as close as possible to the posterior, it is nevertheless very simple compared to the posterior (a good deal of the correlation among parameters is missing because the reference distribution is a product of independent probability distributions). Each ratio in the product above, however, is much easier to estimate because the distribution on top is quite similar to the one on the bottom, a situation in which importance sampling work well.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The \pathname{steppingstone.py} script}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To initiate a steppingstone analysis, use the \cmd{ss} command {\em instead of} the\cmd{mcmc} command. Here is the entire \pathname{steppingstone.py} script. 

\begin{verbatim}
from phycas import * 
mcmc.data_source = 'green.nex'
 
model.type="hky"
model.state_freqs = [0.25, 0.25, 0.25, 0.25]
model.fix_freqs = True
model.kappa = 2.0
model.kappa_prior = BetaPrime(1.0, 1.0)
model.num_rates = 4
model.gamma_shape = 0.5
model.gamma_shape_prior = Exponential(1.0)
 
m1 = model()
m2 = model()
 
model.fix_freqs = False
 
m3 = model()
 
first      = subset(1, 1296, 3)
second = subset(2, 1296, 3)
third     = subset(3, 1296, 3)
 
partition.addSubset(first, m1, "First codon positions")
partition.addSubset(second, m2, "Second codon positions")
partition.addSubset(third, m3, "Third codon positions")
partition()
 
mcmc.fix_topology = True
mcmc.starting_tree_source = TreeCollection(newick='(1:0.31,2:0.10,(3:0.13,(4:0.09,((5:0.10,6:0.20):0.06,(7:0.10,((8:0.05,10:0.11):0.02,9:0.08):0.06):0.04):0.04):0.05):0.03)')
 
ss.nbetaval = 11
mcmc.ncycles = 1000
ss.xcycles = 1000
ss()
sump.file = 'params.p'
sump()
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line-by-line explanation} \label{subsec:steppingstonepyexplanation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Most of this script was described in the previous section (see section~\ref{subsec:partitionpyexplanation}), so we will start with the line containing the \opt{mcmc}{fix\_topology} setting.

\begin{samepage}
\begin{verbatim}
mcmc.fix_topology = True
\end{verbatim}
\pointup\ This line tells Phycas that we wish to fix the tree topology (i.e. not allow the tree topology to change throughout the MCMC analysis). While this is not strictly necessary, it does improve the efficiency of the stepping stone estimation somewhat because the reference distribution can contain terms for each individual branch length parameter, making it a much better match to the posterior. If the topology changes, then a single distribution must be used to describe all branch length parameters. Because some branch lengths are short, and others long, using a single distribution will necessarily have a large variance and not fit any specific branch length marginal posterior distribution as well as a reference distribution dedicated to that particular branch length parameter.
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.starting_tree_source = TreeCollection(newick='(1:0.31,2:0.10,(3:0.13,(4:0.09,((5:0.10,6:0.20):0.06,(7:0.10,((8:0.05,10:0.11):0.02,9:0.08):0.06):0.04):0.04):0.05):0.03)')
\end{verbatim}
\pointup\ Because we are fixing the tree topology, we should specify the tree topology that we wish to use. This line defines a tree topology by creating a \cmd{TreeCollection} object containing a single tree. That single tree is described by the string passed in via the \code{newick} argument. Tree descriptions passed in this way should have taxa identified by numbers (starting with 1), and the numbers should reference the position of the taxon in the data file. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
ss.nbetaval = 11
\end{verbatim}
\pointup\ This specifies the number of ``stepping stones''to use in estimating the marginal likelihood. With this setting, the following 11 beta values would be used: 1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0. 
\end{samepage}

\begin{samepage}
\begin{verbatim}
mcmc.ncycles = 1000
\end{verbatim}
\pointup\ The \cmd{ss} command uses the \cmd{mcmc} to do almost all of the work. Hence, the setting \opt{mcmc}{ncycles} specifies the number of parameter update cycles devoted to each beta value visited. Note that this is the number of cycles per beta value. If you specified \opt{ss}{nbetaval} to be 11 and \opt{mcmc}{ncycles} to be 1000, then the total number of cycles would be 11 times 1000, or 11000 cycles.
\end{samepage}

This example uses 11 beta values, but is this enough? Generally the more stepping stones (i.e. beta values) used, the better the estimate will be, but the quality of the estimate also depends on the quality of the reference distribution. If the reference distribution approximates the posterior well, then fewer beta values are needed (and fewer samples per beta value are needed). If the reference distribution exactly equals the posterior, then only a single sample from the reference distribution (beta = 0.0) would be needed to determine the marginal likelihood exactly, This utopia is never achievable because if one actually knew the posterior distribution exactly, then one would also know the normalizing constant exactly and hence you would not need to estimate it! In practice, it probably makes sense to start with, say, 11 $\beta$ values, and a reasonable number (e.g. 1000) cycles per $\beta$ value. I would do another run, however, doubling both values to see if it makes a big difference. If it does, then probably the first run was not long enough (and perhaps the second run too). 

\begin{samepage}
\begin{verbatim}
ss.xcycles = 1000
\end{verbatim}
\pointup\ This represents the number of extra cycles spent on the posterior distribution. Because the reference distribution is created based on a sample from the posterior, it may make sense to spend a little more time on the first stepping stone (when $\beta = 1$ and the MCMC sampler is exploring the posterior) than on the other $\beta$ values. Our (limited) experience shows that it is not worth spending an exorbitant amount of time on the posterior; a small sample seems to work quite well (assuming the tree topology is fixed).
\end{samepage}

\begin{samepage}
\begin{verbatim}
ss()
\end{verbatim}
\pointup\ This command starts the analysis. It essentially causes the \cmd{mcmc} command to be run for each $\beta$ value visited.
\end{samepage}

\begin{samepage}
\begin{verbatim}
sump.file = 'params.p'
sump()
\end{verbatim}
\pointup\ The \cmd{sump} command is used to summarize the parameter file produced by the \cmd{ss} command and calculate the estimate of the marginal likelihood. The name of the parameter file to summarize must be supplied in the \opt{sump}{file} setting.
\end{samepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Probability Distributions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Probability Distributions}\label{sec:probdist}

Phycas defines several probability distributions. Several of these (Uniform, Beta, Exponential, Gamma, InverseGamma) are commonly used as prior distributions for model parameters. Others (Bernoulli, BetaPrime, Binomial, Normal) are less commonly used as prior distributions in Bayesian phylogenetics, but are nevertheless useful for other reasons. This section briefly describes each of these distributions. 

%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Terminology}
%%%%%%%%%%%%%%%%%%%%%%%%
The \term{support} of a distribution is the set of values for which the density function is greater than zero. A distribution is a \term{discrete distribution} if the number of possible values is finite and each value is associated with a non-zero probability. Discrete distributions are associated with {\em probability} functions, $p(y|\params)$, that serve to provide the probability associated with each possible value. A distribution is a \term{continuous distribution} if the number of possible values is infinite and thus each particular value has probability zero. Continuous distributions are associated with {\em probability density} functions (\term{pdf}s). The pdf, $f(y|\params)$, provides the {\em relative} probability of each value. The pdf is scaled so that it integrates to 1.0, allowing specific {\em areas} under the pdf to be interpreted as probabilities. The \term{indicator function} \one{x=y} takes on the value 1.0 if and only if the condition in the subscript is true (i.e., $x=y$ in this example).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Using probability distributions in Phycas}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In most cases, you will need to prefix the names of distributions with \code{ProbDist}. For example:
%
\begin{verbatim}
model.pinvar_prior = ProbDist.Beta(1,1)
\end{verbatim}
%
You can avoid the need for the prefix by specifically importing the distributions you need at the top of your script. For example:
%
\begin{verbatim}
from phycas.ProbDist import Beta,Gamma
...
model.pinvar_prior = Beta(1,1)
\end{verbatim}
%
Each probability distribution defined in Phycas provides a \code{sample} method that generates a single random deviate from that distribution. For example:
%
\begin{verbatim}
d = ProbDist.Gamma(0.5, 4.0)
d.sample()
11.923011659940444
\end{verbatim}
%
This can be used to get a feel for typical values generated from a distribution. To generate 10 values from a Gamma(0.5, 4.0) distribution, you can use a Python \cmd{for} loop:
%
\begin{verbatim}
d = ProbDist.Gamma(0.5, 4.0)
for i in range(10):
    d.sample()
0.21277867604109485
1.8952730436709666
0.26548236737438019
3.2718729795327026
2.5822707554839197
0.043311257125495065
0.30315706776669216
14.728064587204788
0.085634607314423447
0.10030029917676343
\end{verbatim}
%
It is also possible to get the distribution object to tell you its current mean, variance and standard deviation:
%
\begin{verbatim}
d = ProbDist.Gamma(0.5, 4.0)
d.getMean()
2.0
d.getVar()
8.0
d.getStdDev()
2.8284271247461903
\end{verbatim}
%
To set the parameters of a distribution to match a particular mean and variance, use the \code{setMeanAndVariance} method:
%
\begin{verbatim}
d = ProbDist.Normal(1.0, 1.0)
d.setMeanAndVariance(2.0, 1.0)
d.getMean()
2.0
d.getVar()
1.0
\end{verbatim}
%
To get a description of the distribution and a list of all of its methods, use the \code{help} function:
%
\begin{verbatim}
help(ProbDist.Normal)

This is a class or python type
Represents the univariate normal probability distribution.
The following public methods are available:
getMean
setLot
resetLot
getDistName
getRelativeLnPDF
getVar
lnGamma
getStdDev
clone
getLnPDF
isDiscrete
sample
setMeanAndVariance
setSeed
getCDF
\end{verbatim}
%
To get a description and usage example for a particular function, use \code{help} on the name of the function:
%
\begin{verbatim}
help(ProbDist.Exponential.setMeanAndVariance)

<unbound method Exponential.setMeanAndVariance>

An instance of type instancemethod.

Sets the mean and variance of this distribution. This distribution is
determined entirely by the mean, so the var argument is ignored. The
reason this function requires both mean and variance is for
compatibility with functions of the same name in other distributions.

>>> from phycas.ProbDist import *
>>> b = Exponential(2)
>>> print b.getMean()
0.5
>>> print b.getVar()
0.25
>>> b.setMeanAndVariance(5, 0)
>>> print b.getMean()
5.0
>>> print b.getVar()
25.0
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Probability distributions available in Phycas}\label{availabledistributions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Bernoulli}\label{bernoullidist}\index{Bernoulli distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\arraystretch}{1.5}

This distribution is provided for completeness, but currently there are no parameters in Phycas for which this distribution should be used as a prior. There are only two possible values (0 and 1), so Bernoulli distributions are appropriate for modeling stochastic processes that are characterized by presence vs. absence of something, or success vs. failure.

\begin{tabular}{lcl}
Type:                 & & Discrete, univariate \\
Parameter:            & & $p$ (probability of 1) \\
Probability function: & & $p(y|p) = p \one{y=1} + (1-p) \one{y=0}$ \\
Support:              & & $\{0,1\}$  \\
Expected value:       & & $E[y] = p$ \\
Variance:             & & $\Var(y) = p(1-p)$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Beta}\label{betadist}\index{Beta distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Beta distributions are popular as priors for parameters whose support is the interval [0.0, 1.0], such as proportions. The proportion of invariable sites parameter (often abbreviated pinvar) has a Beta prior by default in Phycas. The quantity $\Gamma(x)$ that appears in the pdf is the \term{gamma function}, which for integral values of $x$ is equal to $(x-1)!$.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\alpha$, $\beta$   \\
Probability density function: & & $f(y|\alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \; \Gamma(\beta)} \; y^{\alpha-1} \; (1-y)^{\beta - 1}$ \\
Support:              & & $[0.0,1.0]$     \\
Expected value:       & & $E[y] = \frac{\alpha}{\alpha + \beta}$ \\
Variance:             & & $\Var(y) = \frac{\alpha \beta}{(\alpha + \beta)^2 \; (\alpha + \beta + 1)}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{BetaPrime}\label{betaprimedist}\index{BetaPrime distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The main use of the BetaPrime distribution in Phycas is to provide a prior distribution for the $\kappa$ parameter (the transition/transversion rate ratio in the HKY model) that is comparable to the prior used by MrBayes. In MrBayes, the $\kappa$ parameter is not given a prior directly; instead, a Beta prior is applied (by default) to the two relative rates in the HKY rate matrix (the transition rate and the transversion rate). Specifying a BetaPrime(a,b) prior on $\kappa$ in Phycas is equivalent to specifying a Beta(a,b) prior on the transition and transversion rates in MrBayes. You are of course free to use any other univariate distribution as a prior for $\kappa$ in Phycas; the BetaPrime distribution is only provided to make it possible to conduct Phcyas analyses that are comparable to MrBayes analyses. Note that the mean of the BetaPrime distribution is undefined if $\alpha$ is less than or equal to 1, and the variance is undefined if $\beta$ is less than or equal to 2.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\alpha$, $\beta$   \\
Probability density function: & & $f(y|\alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \; \Gamma(\beta)} \frac{y^{\alpha-1}}{y^{\alpha + \beta}}$ \\
Support:              & & $[0.0,1.0]$     \\
Expected value:       & & $E[y] = \frac{\alpha}{\beta - 1}$ \\
Variance:             & & $\Var(y) = \frac{\alpha (\alpha + \beta - 1)}{(\beta - 2)(\beta - 1)^2}$
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Binomial}\label{binomialdist}\index{Binomial distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Binomial distribution is not currently useful as a prior distribution in Phycas, and is provided for the sake of completeness. The Binomial distribution is commonly used to model counts of the number of trials satisfying some condition (a ``success''). For example, the number of heads out of 10 (independent) flips of a coin follows a Binomial distribution. The parameter of the distribution is the probability that the condition (e.g. heads) is satisfied on any given trial.

\begin{tabular}{lcl}
Type:                 & & Discrete, univariate \\
Parameters:           & & $p$ (probability of success in any given trial), $n$ (number of trials)    \\
Probability function: & & $p(y|p,n) = {n \choose y} p^y (1-p)^{n-y} $ \\
Support:              & & $\{0,1,\cdots\}$     \\
Expected value:       & & $E[y] = n p$ \\
Variance:             & & $\Var(y) = n p(1-p)$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsubsection{Dirichlet}\label{dirichletdist}\index{Dirichlet distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Dirichlet distribution is used as a prior for quantities that must sum to 1.0, such as state frequencies. The parameters of a Dirichlet distribution are positive real numbers. If all parameters are equal, the Dirichlet distribution is symmetric. For example, a Dirichlet(10,10,10,10) distribution would yield samples of nucleotide frequencies in which no one nucleotide predominates. Furthermore, if all Dirichlet parameters equal 1, then every combination of values has equal probability density. Thus, in a Dirichlet(1,1,1,1) distribution of nucleotide frequencies, extreme frequencies (e.g., 0.001, 0.001, 0.001, 0.997) have just as much of a chance of showing up in a sample as equal frequencies (i.e., 0.25, 0.25, 0.25, 0.25).
\begin{indentednote}
{\bf Important:} For multivariate distributions such as the Dirichlet distribution, you must supply a Python list or tuple rather than a single value as the parameter. Thus, to construct a flat Dirichlet prior for state frequencies, you either need to use an extra set of parentheses (the inner set being recognized by Python as defining a tuple), like this:\par\smallskip
{\small \tt model.state\_freq\_prior = Dirichlet((1.0, 1.0, 1.0, 1.0))}\par\smallskip
or use square brackets (recognized by Python as defining a list), like this:\par\smallskip
{\small \tt model.state\_freq\_prior = Dirichlet([1.0, 1.0, 1.0, 1.0])}
\end{indentednote}
\begin{tabular}{lcl}
Type:                 & & Continuous, multivariate \\
Parameters:           & & $c_1, c_2, \cdots, c_n \; (0 < c_i < \infty)$    \\
                      & & $c_{\cdot} = \sum_{i=1}^{n} c_i$ \\
Probability function: & & $f(y_1, y_2, \cdots, y_n|c_1, c_2, \cdots, c_n) = p_1 p_2 \cdots p_n
\left(
	\frac{\left(p_1 y_1\right)^{c_1-1} \; \left(p_2 y_2\right)^{c_2-1} \; \cdots \; \left(p_n y_n\right)^{c_n-1}}
	{\frac{\Gamma(c_1) \Gamma(c_2) \cdots \Gamma(c_n)}{\Gamma(\ccdot)}}
\right)$ \\
Support:              & & $[0,1]^n$     \\
Expected value:       & & $E[y_i] = \frac{c_i}{\ccdot}$ \\
Variance:             & & $\Var(y_i) = \frac{c_i (\ccdot - c_i)}{\ccdot^2 (\ccdot + 1)}$ \\
Covariance:           & & $\Cov(y_i,y_j) = \frac{-c_i c_j}{\ccdot^2 (\ccdot + 1)}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Exponential}\label{exponentialdist}\index{Exponential distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Exponential distribution is a special case of the Gamma distribution (in which the shape parameter equals 1.0). The Exponential distribution is a common prior for parameters whose support equals the positive real numbers, such as edge lengths, transition/transversion rate ratio ($\kappa$), nonsynonymous/synonymous rate ratio ($\omega$), the shape parameter of the discretized Gamma distribution used to model among-site rate heterogeneity, GTR model relative rates (exchangeabilities), and unnormalized parameters governing base frequencies.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameter:            & & $\lambda$ (rate; a.k.a. hazard)    \\
Probability function: & & $f(y|\lambda) = \lambda e^{-\lambda y}$ \\
Support:              & & $[0.0,\infty)$     \\
Expected value:       & & $E[y] = 1/\lambda$ \\
Variance:             & & $\Var(y) = 1/\lambda^2$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Gamma}\label{gammadist}\index{Gamma distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Gamma distribution (or its special case, the Exponential distribution) is commonly used as a prior distribution for parameters defined on the positive half of the real number line. The Gamma distribution assigns probability zero for any value less than zero. Gamma distributions with shapes less than 1 have a pdf mode greater than zero. Those with shape equal to 1 are identical to Exponential distributions. In this case, the highest point reached by the pdf is $\beta$ and occurs at the value zero. If the shape is greater than 1, the pdf approaches infinity as zero is approached. The quantity $\Gamma(\alpha)$ that appears in the pdf is the \term{gamma function}, which for integral values of $\alpha$ is equal to $(\alpha-1)!$.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\alpha$ (shape), $\beta$ (scale)    \\
Probability function: & & $f(y|\alpha,\beta) = \frac{y^{\alpha - 1} \; e^{-y/\beta}}{\beta^{\alpha} \; \Gamma(\alpha)}$ \\
Support:              & & $[0.0,\infty)$     \\
Expected value:       & & $E[y] = \alpha \beta$ \\
Variance:             & & $\Var(y) = \alpha \beta^2$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{InverseGamma}\label{inversegammadist}\index{Inverse gamma distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Inverse Gamma distribution with parameters $\alpha$ and $\beta$ is the distribution of the quantity $1/y$ if $y$ has a Gamma($\alpha,\beta$) distribution. In Phycas, the Inverse Gamma distribution is primarily used as an edge length hyperprior (see section~\ref{hierarchicalmodels} on hierarchical models). The mean of an Inverse Gamma distribution is undefined unless the shape parameter $\alpha$ is greater than 1; the variance is undefined unless $\alpha > 2$.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\alpha$ (shape), $\beta$ (scale)    \\
Probability function: & & $f(y|\alpha,\beta) = \frac{(1/y)^{\alpha + 1} \; e^{-(1/y)/\beta}}{\beta^{\alpha} \; \Gamma(\alpha)}$ \\
Support:              & & $[0.0,\infty)$     \\
Expected value:       & & $E[y] = \frac{1}{\beta \;(\alpha-1)}$ \\
Variance:             & & $\Var(y) = \frac{1}{\beta^2 \; (\alpha-1)^2 \; (\alpha-2)}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Lognormal}\label{lognormaldist}\index{Lognormal distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Specifying a Lognormal($\mu$,$\sigma$) distribution for a random variable $Y$ means that $\log(Y)$ is normally distributed with mean $\mu$ and variance $\sigma^2$. It is important to remember that $\mu$ and $\sigma$ do {\em not} represent the mean and variance of the variable $Y$ that is distributed lognormally (tricky!). Unlike the Normal distribution, which has support ($-\infty$,$\infty$), the support for Lognormal is [0,$\infty$), which makes it applicable to the same parameters as the Gamma distribution.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\mu$ (mean of $\log(Y)$), $\sigma$ (standard deviation of $\log(Y)$)    \\
Probability function: & & $f(y|\mu,\sigma) = \frac{1}{y \sqrt{2 \pi \sigma^2}} e^{-\frac{(\log(y)-\mu)^2}{2 \sigma^2}}$ \\
Support:              & & $[0,\infty)$     \\
Expected value:       & & $E[y] = e^{\mu + \frac{\sigma^2}{2}}$ \\
Variance:             & & $\Var(y) = \left( e^{\sigma^2} - 1 \right) e^{2 \mu + \sigma^2}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Normal}\label{normaldist}\index{Normal distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The normal distribution does not get a lot of use as a prior distribution because its support includes the negative real numbers, and most parameters used in Bayesian phylogenetics only make sense if they are positive.

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $\mu$ (mean), $\sigma$ (standard deviation)    \\
Probability function: & & $f(y|\mu,\sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(y-\mu)^2}{2 \sigma^2}}$ \\
Support:              & & $(-\infty,\infty)$     \\
Expected value:       & & $E[y] = \mu$ \\
Variance:             & & $\Var(y) = \sigma^2$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{RelativeRate}\label{relratedist}\index{Relative rate distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Relative Rate Distribution is used as a prior for the subset relative rates in a partitioned data model. The Relative Rate Distribution is very similar to a Dirichlet distribution. A vector of relative rates has mean equal to 1.0, however, which makes a Dirichlet distribution inappropriate (the sum, not the mean, of the components of a Dirichlet-distributed random variable is 1). The distinction between a Relative Rate distribution and a Dirichlet distribution mainly arises in the model selection context when the Stepping Stone method is begin used to estimate marginal (model) likelihoods. In the Stepping Stone method, constants that appear in prior distribution probability density functions must be fully specified. This is not necessary for Bayesian MCMC analyses because such constants cancel out.

The quantities $p_i$ below are the subset weights. Ordinarily, $p_i$ is simply the proportion of sites assigned to subset $i$. The parameter $c_i$ is analogous to the corresponding parameter in a Dirichlet distribution.
\begin{indentednote}
{\bf Important:} For multivariate distributions such as the relative rate distribution, you must supply a Python list or tuple rather than a single value as the parameter. Thus, to construct a flat RelativeRate prior for partition subset relative rates, you either need to use an extra set of parentheses (the inner set being recognized by Python as defining a tuple), like this:\par\smallskip
{\small \tt partition.subset\_relrates\_prior = RelativeRate((1.0, 1.0, 1.0, 1.0))}\par\smallskip
or use square brackets (recognized by Python as defining a list), like this:\par\smallskip
{\small \tt partition.subset\_relrates\_prior = RelativeRate([1.0, 1.0, 1.0, 1.0])}\par\smallskip
Note that because the default is to use a RelativeRate prior for partition subset relative rates, you need not worry about specifying anything for \opt{partition}{subset\_relrates\_prior} unless you want to create a prior that is more informative than the default (in which all parameters in the supplied tuple equal 1.0).
\end{indentednote}
\begin{tabular}{lcl}
Type:                 & & Continuous, multivariate \\
Parameters:           & & $c_1, c_2, \cdots, c_n \; (0 < c_i < \infty)$    \\
                      & & $c_{\cdot} = \sum_{i=1}^{n} c_i$    \\
Probability function: & & $f(y_1, y_2, \cdots, y_n|c_1, c_2, \cdots, c_n) = p_1 p_2 \cdots p_n
\left(
	\frac{\left(p_1 y_1\right)^{c_1-1} \; \left(p_2 y_2\right)^{c_2-1} \; \cdots \; \left(p_n y_n\right)^{c_n-1}}
	{\frac{\Gamma(c_1) \Gamma(c_2) \cdots \Gamma(c_n)}{\Gamma(c_{\cdot})}}
\right)$ \\
Support:              & & $[0,\infty)^n$     \\
Expected value:       & & $E[y_i] = \frac{c_i}{p_i c_{\cdot}}$ \\
Variance:             & & $\Var(y_i) = \frac{c_i (\ccdot - c_i)}{p_i^2 \ccdot^2 (\ccdot + 1)}$ \\
Covariance:           & & $\Cov(y_i,y_j) = \frac{-c_i c_j}{p_i p_j \ccdot^2 (\ccdot + 1)}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Uniform}\label{uniform}\index{Uniform distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Uniform distribution has been used extensively as a prior for many different continuous model parameters; however, because Uniform distributions must be truncated in order to be proper, their use as prior distributions can have some surprising effects (see \citet{Felsenstein2004} for a good discussion of the problems with truncated Uniform priors).

\begin{tabular}{lcl}
Type:                 & & Continuous, univariate \\
Parameters:           & & $a$ (lower bound), $b$ (upper bound)    \\
Probability function: & & $f(y|a,b) = \frac{1}{b-a}$ \\
Support:              & & $[a,b]$     \\
Expected value:       & & $E[y] = \frac{a + b}{2}$ \\
Variance:             & & $\Var(y) = \frac{(b - a)^2}{12}$ 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Models %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}\label{sec:models}

Phycas implements the standard suite of nucleotide models: JC, F81, K80, HKY, and GTR with their I, G and I+G rate heterogeneity versions. The following sections illustrate how to set up each of the five basic classes of models listed above and how to add discrete gamma and/or proportion of invariable sites rate heterogeneity to any model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The basic substitution models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%
\subsubsection{JC}
%%%%%%%%%%%%%%%%%%
The JC model \citep{JukesCantor1969} constrains base frequencies and relative substitution rates to be equal.

\begin{samepage}
{\bf Rate matrix}
$${\bf R} = \bordermatrix{ &     A     &     C     &     G     &   T       \cr
                         A & -3 \alpha &  \alpha   &  \alpha   &  \alpha   \cr
                         C &  \alpha   & -3 \alpha &  \alpha   &  \alpha   \cr
                         G &  \alpha   &  \alpha   & -3 \alpha &  \alpha   \cr
                         T &  \alpha   &  \alpha   &  \alpha   & -3 \alpha \cr}$$
\end{samepage}

\begin{samepage}
{\bf Choosing the JC model in Phycas}
\begin{verbatim}
model.type = 'jc'
\end{verbatim}
\end{samepage}

%%%%%%%%%%%%%%%%%%%
\subsubsection{F81}
%%%%%%%%%%%%%%%%%%%

The F81 model \citep{Felsenstein1981} constrains relative substitution rates ($\mu$) to be equal but allows base frequencies ($\bm \pi$) to vary. Fixing $\pi_A = \pi_C = \pi_G = \pi_T = 0.25$ makes the F81 model equivalent to the JC model (note that $\mu = 4 \alpha$).

\begin{samepage}
{\bf Rate matrix}
$${\bf R} = \bordermatrix{ &       A      &       C       &       G       &       T       \cr
                         A &    \Rii{A}   & \pi_C \; \mu  & \pi_G \; \mu  & \pi_T \; \mu  \cr
                         C & \pi_A \; \mu &    \Rii{C}    & \pi_G \; \mu  & \pi_T \; \mu  \cr
                         G & \pi_A \; \mu & \pi_C \; \mu  &    \Rii{G}    & \pi_T \; \mu  \cr
                         T & \pi_A \; \mu & \pi_C \; \mu  & \pi_G \; \mu  &     \Rii{T}   \cr}$$                                                         
\end{samepage}

\begin{samepage}
{\bf Choosing the F81 model in Phycas}
\begin{verbatim}
model.type = 'hky'
model.kappa = 1.0
model.fix_kappa = True
\end{verbatim}
\end{samepage}

%%%%%%%%%%%%%%%%%%%
\subsubsection{K80}
%%%%%%%%%%%%%%%%%%%
The K80 model \citep{Kimura1980} constrains base frequencies to be equal but allows the rate of transitions to differ from the rate of transversions by a factor $\kappa = \alpha/\beta$.

\begin{samepage}
{\bf Rate matrix}
$${\bf R} = \bordermatrix{ &         A          &         C          &        G          &         T          \cr
                         A & -\beta(\kappa + 2) &  \beta             &  \beta \kappa     &  \beta             \cr
                         C &  \beta             & -\beta(\kappa + 2) &  \beta            &  \beta \kappa      \cr
                         G &  \beta \kappa      &  \beta             & -\beta(\kappa + 2)&  \beta             \cr
                         T &  \beta             &  \beta \kappa      &  \beta            & -\beta(\kappa + 2) \cr}$$
\end{samepage}

\begin{samepage}
{\bf Choosing the K80 model in Phycas}
\begin{verbatim}
model.type = 'hky'
model.state_freqs = [0.25, 0.25, 0.25, 0.25]
model.fix_freqs = True
\end{verbatim}
\end{samepage}

%%%%%%%%%%%%%%%%%%%
\subsubsection{HKY}
%%%%%%%%%%%%%%%%%%%
The HKY model \citep{HasegawaKishinoYano1985} allows base frequencies to be unequal and the transition/transversion rate ratio $\kappa$ to be some value other than 1.0.

\begin{samepage}
{\bf Rate matrix}
$${\bf R} = \bordermatrix{ &       A      &       C       &       G       &       T       \cr
A & -\beta (\pi_Y + \pi_G \kappa) & \pi_C \; \beta  & \pi_G \; \beta \; \kappa  & \pi_T \; \beta  \cr
C & \pi_A \; \beta & -\beta (\pi_R + \pi_T \kappa) & \pi_G \; \beta  & \pi_T \; \beta \; \kappa  \cr
G & \pi_A \; \beta \; \kappa & \pi_C \; \beta  & -\beta (\pi_Y + \pi_A \kappa) & \pi_T \; \beta  \cr
T & \pi_A \; \beta & \pi_C \; \beta \; \kappa  & \pi_G \; \beta  & -\beta (\pi_R + \pi_C \kappa) \cr}$$
\end{samepage}

\begin{samepage}
{\bf Choosing the HKY model in Phycas}
\begin{verbatim}
model.type = 'hky'
\end{verbatim}
\end{samepage}

%%%%%%%%%%%%%%%%%%%
\subsubsection{GTR}
%%%%%%%%%%%%%%%%%%%
The GTR model \citep{LanavePreparataSacconeSerio1984} allows base frequencies to be unequal and all six relative substitution rates ($a$, $b$, $c$, $d$, $e$ and $f$) to be different.

\begin{samepage}
{\bf Rate matrix}
$${\bf R} = \bordermatrix{ &       A      &       C       &       G       &       T       \cr
A & -(\pi_C a + \pi_G b + \pi_T c) & \pi_C \; a  & \pi_G \; b  & \pi_T \; c  \cr
C & \pi_A \; a & -(\pi_A a + \pi_G d + \pi_T e) & \pi_G \; d  & \pi_T \; e  \cr
G & \pi_A \; b & \pi_C \; d  & -(\pi_A b + \pi_C d + \pi_T f) & \pi_T \; f  \cr
T & \pi_A \; c & \pi_C \; e  & \pi_G \; f  & -(\pi_A c + \pi_C e + \pi_G f) \cr}$$
\end{samepage}

\begin{samepage}
{\bf Choosing the GTR model in Phycas}
\begin{verbatim}
model.type = 'gtr'
\end{verbatim}
\end{samepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Adding rate heterogeneity}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Proportion of invariable-sites}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A ``$+I$'' version \citep{Reeves1992} of any of the basic substitution models means that each site is viewed as having probability $\pinvar$ of being invariable (i.e. substitution rate zero). This is one common way to accommodate among-site rate heterogeneity in nucleotide sequence data.

\begin{verbatim}
model.pinvar_model = True
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Discrete gamma}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A ``$+G$'' version \citep{Yang1994} of any of the basic substitution models means that the model assumes that the distribution of rates across sites conforms to a Gamma distribution having mean 1.0. In Phycas (as in most phylogenetic software), a discretized Gamma distribution is used in practice, and implemented as an equal weight mixture model (each site is assumed to belong to each rate category with probability $1/\ncateg$). The number of rate categories $\ncateg$ is set using the \opt{model}{num\_rates} option. If \opt{model}{num\_rates} is set to any value greater than 1, the model becomes a $+G$ version.

\begin{verbatim}
model.num_rates = 4
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Design principles %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Design principles}\label{sec:designprinciples}

The design principles underlying Phycas are presented best as a series of questions and answers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Why was Phycas written as an extension to Python?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{Why Python?}Most phylogenetic analyses take a considerable amount of time to run, and thus most phylogenetic analysis software provides a mechanism for batch processing. 
Batch processing is ordinarily accomplished through the use of a command syntax of some sort that allows the user to specify the sequence of commands to run. For example, PAUP* allows PAUP blocks to be placed in NEXUS files. The user can run an analysis without manual intervention by simply executing such a file containing PAUP* commands. 
This mode has the added benefit of creating a record of exactly the analysis performed, so that later on when the reviews come back and you are trying to respond to reviewers' concerns, you can actually recall what you did! 
Using menu-driven programs makes this difficult unless the software saves a history of all keystrokes and menu selections. 
Other popular programs have their own, private command languages. 
For example, MrBayes uses MRBAYES blocks in NEXUS files, Hy-Phy uses a C-like language, and Beast uses xml as its medium for communicating commands. One reason we chose to extent Python is so that we could use an existing, well-documented, widely-available computing language as the command language for Phycas. There are many books available on using Python, which means we do not have to provide all the details, and Python is a very powerful computing language, meaning you can write very sophisticated scripts that do anything your heart desires in your phylogenetic analysis. With the phylogenetic library of tools supplied by Phycas, you can even invent new phylogenetic methods if you are so inclined. 
There is, of course, some program-specific learning you must do in order to use Phycas; just having a prior knowledge of Python will not save you from reading this manual to learn what Phycas offers and how to access those features.
We feel, however, that using a powerful, existing computing language to communicate with Phycas instead of ``rolling our own'' program-specific language was a very good idea.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Why is there no graphical user interface (GUI)?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{graphical user interface}Due to the large scale at which DNA sequencing is performed these days, and the increasing desire to ``pipeline'' analyses, we felt that using a script-based approach would best serve the needs of potential users in the near and distant future. Python is already installed on most unix-based operating systems (including Linux and MacIntosh OSX), and thus Phycas can be easily inserted into bioinformatics pipeline applications. Although it does not come pre-installed on new systems, Python is easy to install on \trademark{Windows}-based PCs, and thus Phycas can be used easily on any workstation or laptop. While many users like user-friendly GUIs with pull-down menus and dialog boxes, software that depends on a GUI has certain disadvantages: (1) cannot be pipelined easily; (2) cannot be run on a remote cluster; and (3) often does not allow one to save a record of the exact analysis performed. One of the strong benefits of a GUI is that it allows experimentation and visualization. Phycas provides for visualization by outputting trees and plots in the form of PDF files. While not quite as appealing as an on-screen visual representation, PDF files provide what most of us really need: the ability to insert a publication-quality figure into a manuscript, or load artwork into other programs for manipulation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Is Phycas slower than MrBayes?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
All scripting-based languages (R, Python, Perl, Ruby) are relatively slow compared to compiled languages such as C and C++. Fortunately, the Boost Python library (\url{http://www.boost.org/libs/python/doc/}) has made it easy to write the parts of Phycas that need to be fast in C++ and export these routines so that they can be called from Python. As a result, Phycas competes favorably with any phylogenetic software application out there in terms of speed. If you make speed comparisons of Phycas to other programs, be sure to compare them in a fair way. Phycas uses a different definition of ``generation'' than does MrBayes, for example. Because a ``cycle'' in Phycas is equivalent to more than 100 ``generations'' in MrBayes, it is easy to conclude that Phycas is slow compared to MrBayes. To be fair, compare instead the time required for some (large) number likelihood calculations under comparable models. Phycas makes this easy by reporting the number of likelihood calculations performed and the time required at the end of an MCMC analysis\index{comparing speed}. The number of likelihood calculations used by MrBayes for a single chain equals simply the number of generations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Settings}\label{sec:phycassettings}
\input{cmdsettings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Installing Phycas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Installing Phycas}\label{sec:install}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Instructions for \trademark{Windows} users} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

These instructions assume you are using \trademark{Windows} \trademark{XP} or \trademark{Vista}.

\subsubsection{\trademark{Windows} console} \label{subsubsec:winconsole}

One very handy feature that does not come with \trademark{Windows} is the ability to open a command console by using the right-click speed menu in \trademark{Explorer}. The web site \url{http://www.commandline.co.uk/cmdhere/} describes how to add this functionality, which will make Phycas {\em much} easier to use (it is not required, however, in order to use Phycas). The basic procedure is to create a file named \pathname{cmdhere.reg} with the following text (or download the file from the web site above):
%
\begin{verbatim}
REGEDIT4

[HKEY_CLASSES_ROOT\*\shell\cmdhere]
@="Cmd&Here"

[HKEY_CLASSES_ROOT\*\shell\cmdhere\command]
@="cmd.exe /c start cmd.exe /k pushd \"%L\\..\""

[HKEY_CLASSES_ROOT\Folder\shell\cmdhere]
@="Cmd&Here"

[HKEY_CLASSES_ROOT\Folder\shell\cmdhere\command]
@="cmd.exe /c start cmd.exe /k pushd \"%L\""
\end{verbatim}
%
Assuming that you saved this file with the extension \pathname{.reg}, the \trademark{Windows} operating system will know what to do with it. Double-click the name of the file in \trademark{Windows} \trademark{Explorer}, and the required registry entry will be made. \warning{making changes to your system's registry is a bit risky, and we take no responsibility for any damage your system may incur by following these directions!} That said, this worked fine for us and saves an enormous amount of time. \trademark{Windows} offers a PowerToy (\url{http://www.microsoft.com/windowsxp/downloads/powertoys/xppowertoys.mspx}) for \trademark{XP} that does something similar. While perhaps safer to install, it is somewhat frustrating to use because if you are already inside a directory in which you want to open a console, you must first go up one level in order to open a console window for that directory.

\subsubsection{Installing Python under \trademark{Windows}}

Before you go to the trouble of downloading and installing Python, make sure you do not already have Python installed on your Windows system. From the Start button, choose \menu{All Programs}, then \menu{Accessories} and finally \menu{Command Prompt}. Type \code{python -V} in the console window that appears, and if a phrase such as \code{Python 2.5.1} appears, then you already have Python installed! Most Windows users will probably see \code{'python' is not recognized as an internal or external command, operable program or batch file.} In this case, you need to visit \url{http://python.org} and download and install the latest version of Python (version \currPyVersion\ as of this writing). \warnNoPyThree

\subsubsection{Installing Phycas under \trademark{Windows}}

Visit the Download section of the Phycas web site \url{http://phycas.org/} and download the Windows installer. If you are using Windows XP, double-click the installer to install Phycas. If using Vista, right-click the installer and choose to install as Administrator. The installer will attempt to identify the location of Python on your system, and if it fails to find Python will abort the installation. Assuming it can find Python, it will install Phycas into the \pathname{Lib/site-packages} directory of that Python installation. 

\subsubsection{Locating the ``Phycas Installation Folder'' under \trademark{Windows}} \label{subsubsec:installfolderwindows}

You will find a Phycas section in the menu that appears when you choose \menu{Start} and \menu{All Programs}. Included in the \menu{Start/All Programs/Phycas} menu is an item named \menu{Phycas Installation Folder}. Choosing this menu item will open \trademark{Windows} (file) Explorer to the ``Phycas Installation Folder'' mentioned in the tutorial.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Instructions for MacIntosh Users}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

These instructions assume you are using MacOS 10.4 or later.

\subsubsection{The iTerm terminal application}

Bundled with Phycas is a terminal application called iTerm. The iTerm application is an open-source replacement for the Terminal application with which you may be familiar (and which comes with the MacOS). While it is possible to use Phycas from Terminal, we recommend strongly that you use the iTerm application that comes with Phycas. The iTerm application starts automatically when you click on the icon labeled ``Phycas'' (see below) or drop a script file onto the icon. The main reason for using the bundled iTerm application is that it starts Python and imports phycas for you automatically when it is started.

\subsubsection{Installing Python on a Mac}

If you are using MacOS 10.4, and haven't installed Python yourself, your Mac probably has Python 2.3 installed. To find out, open a terminal window (you can find the Terminal app in the Utilities folder, which is itself a subfolder of the \pathname{Applications} folder) and type \code{python -V}. If the version of Python is 2.3, you will need to visit \url{http://python.org} and download and install the latest version of Python (version \currPyVersion\ as of this writing). \warnNoPyThree

\subsubsection{Installing Phycas on a Mac}

Visit the Download section of the Phycas web site \url{http://phycas.org/} and download the MacOS DMG file. Once the DMG file has been downloaded, double-click it to mount it. Inside the DMG, you should find several files (Figure~\ref{phycasdmg}). Copy the ``file'' named \pathname{Phycas} (which is actually a special ``application bundle'' folder named \phycasapp, but the operating system hides the \pathname{.app} part of the name) to your \pathname{Applications} folder and the file named \pathname{manual.pdf} to a folder of your choice. To start Phycas, double-click the \phycasapp\ application or, alternatively, drop a script file with Phycas commands onto it. \important{When you start Phycas, you are actually starting an application named iTerm that has been bundled with the Phycas Python libraries. Thus, the menu items you see are iTerm menu items (including the \menu{Update...} menu item)}. With this MacOS version, you need not type the \code{from phycas import *} command because this is done for you when you double-click \phycasapp.

\subsubsection{Locating the ``Phycas Installation Folder'' on a Mac} \label{subsubsec:installfoldermac}

The ``Phycas Installation Folder'' that is mentioned in the tutorial is inside the \phycasapp\ application bundle. MacOS tries to make it difficult for you to see inside application bundles, but clicking on the \phycasapp\ bundle while pressing the \keycmd{Ctrl} will produce a menu, and choosing the \menu{Show Package Contents} item on that menu will allow you to view the contents of the application bundle folder. Once inside \phycasapp, double-click on the \pathname{Contents} folder, then the \pathname{Resources} folder to find the Phycas Installation folder, which is simply named \path{phycas}.

%
% Figure "phycasdmg"
%
\begin{figure}[t]
\begin{center}
\begin{minipage}{5.in}
\hfil\includegraphics[scale=0.5]{images/phycasdmg}\hfil
\caption{\small The Phycas DMG file after it has been mounted.}
\label{phycasdmg}
\end{minipage}
\end{center}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% References %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{References}\addcontentsline{toc}{section}{References}
\renewcommand{\bibsection}{}
\bibliography{manual}

\printindex

\end{document}
